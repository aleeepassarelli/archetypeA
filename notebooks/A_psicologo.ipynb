{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT5ULyf+f5U3Lk2Z1nBiIs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleeepassarelli/archetypeA/blob/main/notebooks/A_psicologo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öóÔ∏è Archetype A: Engenharia Latente Sem√¢ntica (Demo)\n",
        "\n",
        "> *\"Entre forma e fun√ß√£o, a cogni√ß√£o se operacionaliza.\" ‚Äî Aledev*\n",
        "\n",
        "Este notebook demonstra a execu√ß√£o pr√°tica de um **Arqu√©tipo Cognitivo (Classe 7 - Transcend√™ncia)** utilizando a engine `archetype-a` e o modelo **Gemini Pro**.\n",
        "\n",
        "### O Experimento: `A_Psicologo`\n",
        "Vamos instanciar um agente terap√™utico que segue o ciclo da **Alquimia Herm√©tica**."
      ],
      "metadata": {
        "id": "7-KDT2pvF-f3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öóÔ∏è Archetype A: Engenharia Latente Sem√¢ntica (Demo)\n",
        "\n",
        "> *\"Entre forma e fun√ß√£o, a cogni√ß√£o se operacionaliza.\" ‚Äî Aledev*\n",
        "\n",
        "Este notebook demonstra a execu√ß√£o pr√°tica de um **Arqu√©tipo Cognitivo (Classe 7 - Transcend√™ncia)** utilizando a engine `archetype-a` e o modelo **Gemini Pro**.\n",
        "\n",
        "### O Experimento: `A_Psicologo`\n",
        "Vamos instanciar um agente terap√™utico que segue o ciclo da **Alquimia Herm√©tica**."
      ],
      "metadata": {
        "id": "2cYWeOxSFXGs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry3CUKKdFVRu"
      },
      "outputs": [],
      "source": [
        "# 1. Instala√ß√£o da Engine ELS (Direto do GitHub)\n",
        "# Isso garante que estamos usando a √∫ltima vers√£o da sua biblioteca\n",
        "!pip install -q git+https://github.com/aleeepassarelli/archetype-a.git\n",
        "!pip install -q -U google-generativeai rich\n",
        "\n",
        "# 2. Baixar o Arqu√©tipo Oficial (Fonte da Verdade)\n",
        "import os\n",
        "if not os.path.exists('A_Psicologo.yaml'):\n",
        "    !wget -q https://raw.githubusercontent.com/aleeepassarelli/archetype-a/main/archetypes/A_Psicologo.yaml -O A_Psicologo.yaml\n",
        "\n",
        "print(\"‚úÖ Ambiente configurado.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Autentica√ß√£o Gemini\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # Certifique-se de adicionar 'GOOGLE_API_KEY' nos Segredos do Colab (√≠cone da chave üîë √† esquerda)\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"‚úÖ Conex√£o com Gemini estabelecida.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Configure sua API Key no menu 'Secrets' do Colab.\")"
      ],
      "metadata": {
        "id": "5bZUIsPRFcE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Execu√ß√£o da Engine\n",
        "from archetype_a.engine import ArchetypeEngine\n",
        "from rich.console import Console\n",
        "from rich.markdown import Markdown\n",
        "\n",
        "# Definir o Conector (Adaptador para o Gemini)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "def call_gemini(prompt, context):\n",
        "    try:\n",
        "        # A engine manda o prompt estruturado e o contexto\n",
        "        response = model.generate_content(prompt + \"\\n\\n\" + context)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"[Erro na LLM]: {e}\"\n",
        "\n",
        "# Instanciar e Rodar\n",
        "engine = ArchetypeEngine(model_connector=call_gemini)\n",
        "\n",
        "contexto_paciente = \"\"\"\n",
        "Sinto que meu trabalho n√£o tem sentido, mas tenho medo de sair e passar necessidade.\n",
        "Tenho raiva do meu chefe, mas no fundo acho que a culpa √© minha incompet√™ncia.\n",
        "\"\"\"\n",
        "\n",
        "print(\"üß† Iniciando Sess√£o Alqu√≠mica...\\n\")\n",
        "result = engine.run(\"A_Psicologo.yaml\", contexto_paciente)\n",
        "\n",
        "# Exibir Resultado Final (A Coagula√ß√£o)\n",
        "print(\"\\nüìù RESULTADO FINAL (RUBEDO):\")\n",
        "print(result.final_state)"
      ],
      "metadata": {
        "id": "qm9a3dC_Fg7o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}